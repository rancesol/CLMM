{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit halo mass to shear profile: 2. realistic data and wrong model\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use `clmm` to estimate a WL halo mass from observations of a galaxy cluster. It uses several functionalities of the support `mock_data` module to produce datasets of increasing complexity. This notebook also demonstrates the bias introduced on the reconstructed mass by a naive fit, when the redshift distribution of the background galaxies is not properly accounted for in the model. Organization of this notebook goes as follows:\n",
    "\n",
    "- Setting things up, with the proper imports.\n",
    "- Generating 3 datasets: an ideal dataset (dataset1) similar to that of Example1 (single source plane); an ideal dataset but with source galaxies following the Chang et al. (2013) redshift distribution (dataset2); a noisy dataset where photoz errors and shape noise are also included (dataset3). \n",
    "- Computing the binned reduced tangential shear profile, for the 3 datasets, using logarithmic binning.\n",
    "- Setting up the \"single source plane\" model to be fitted to the 3 datasets. Only dataset1 has a single source plane, so we expect to see a bias in the reconstructed mass when using this model on datasets 2 and 3. \n",
    "- Perform a simple fit using `scipy.optimize.curve_fit` and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: import clmm\n",
    "except:\n",
    "    import notebook_install\n",
    "    notebook_install.install_clmm_pipeline(upgrade=False)\n",
    "    import clmm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from clmm.support.sampler import fitters\n",
    "\n",
    "clmm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `clmm`'s core modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm.dataops as da\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.theory as theory\n",
    "from clmm import Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import a support modules for a specific data sets.\n",
    "`clmm` includes support modules that enable the user to generate mock data in a format compatible with `clmm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support import mock_data as mock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mock data, we need to define a true cosmology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_cosmo = Cosmology(H0 = 70.0, Omega_dm0 = 0.27 - 0.045, Omega_b0 = 0.045, Omega_k0 = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set some parameters for a mock galaxy cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = mock_cosmo\n",
    "cluster_m = 1.e15 # M200,m [Msun]\n",
    "cluster_z = 0.3\n",
    "concentration = 4\n",
    "ngals = 10000\n",
    "Delta = 200\n",
    "cluster_ra = 20.0\n",
    "cluster_dec = 70.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `mock_data` support module to generate 3 galaxy catalogs:\n",
    "- `ideal_data`: all background galaxies at the same redshift.\n",
    "- `ideal_data_z`: galaxies distributed according to the Chang et al. (2013) redshift distribution.\n",
    "- `noisy_data_z`: `ideal_data_z` + photoz errors + shape noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_data = mock.generate_galaxy_catalog(cluster_m, cluster_z, concentration, cosmo, 0.8, ngals=ngals, \n",
    "                                          cluster_ra=cluster_ra, cluster_dec=cluster_dec)\n",
    "ideal_data_z = mock.generate_galaxy_catalog(cluster_m, cluster_z, concentration, cosmo,'chang13', ngals=ngals,\n",
    "                                            cluster_ra=cluster_ra, cluster_dec=cluster_dec)\n",
    "noisy_data_z = mock.generate_galaxy_catalog(cluster_m, cluster_z, concentration, cosmo, 'chang13', \n",
    "                                            shapenoise=0.05, \n",
    "                                            photoz_sigma_unscaled=0.05, ngals=ngals,\n",
    "                                            cluster_ra=cluster_ra, cluster_dec=cluster_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The galaxy catalogs are converted to a `clmm.GalaxyCluster` object and may be saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = \"CL_ideal\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec,\n",
    "                               cluster_z, ideal_data)\n",
    "gc_object.save('ideal_GC.pkl')\n",
    "\n",
    "cluster_id = \"CL_ideal_z\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec,\n",
    "                               cluster_z, ideal_data_z)\n",
    "gc_object.save('ideal_GC_z.pkl')\n",
    "\n",
    "cluster_id = \"CL_noisy_z\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec,\n",
    "                               cluster_z, noisy_data_z)\n",
    "gc_object.save('noisy_GC_z.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any saved `clmm.GalaxyCluster` object may be read in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl1 = clmm.GalaxyCluster.load('ideal_GC.pkl') # all background galaxies at the same redshift\n",
    "cl2 = clmm.GalaxyCluster.load('ideal_GC_z.pkl') # background galaxies distributed according to Chang et al. (2013)\n",
    "cl3 = clmm.GalaxyCluster.load('noisy_GC_z.pkl') # same as cl2 but with photoz error and shape noise\n",
    "\n",
    "print(\"Cluster info = ID:\", cl2.unique_id, \"; ra:\", cl2.ra, \"; dec:\", cl2.dec, \"; z_l :\", cl2.z)\n",
    "print(\"The number of source galaxies is :\", len(cl2.galcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(cl2.galcat['z'], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing shear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.compute_tangential_and_cross_components` calculates the tangential and cross shears for each source galaxy in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, g_t1, g_x1 = cl1.compute_tangential_and_cross_components()\n",
    "theta2, g_t2, g_x2 = cl2.compute_tangential_and_cross_components()\n",
    "theta2, g_t3, g_x3 = cl3.compute_tangential_and_cross_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radially binning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = da.make_bins(0.7, 4, 15, method='evenlog10width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.make_radial_profile` evaluates the average shear of the galaxy catalog in bins of radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile1 = cl1.make_radial_profile(\"Mpc\", bins=bin_edges,cosmo=cosmo)\n",
    "profile2 = cl2.make_radial_profile(\"Mpc\", bins=bin_edges,cosmo=cosmo)\n",
    "profile3 = cl3.make_radial_profile(\"Mpc\", bins=bin_edges,cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `clmm.dataops.make_radial_profile` on a `clmm.GalaxyCluster` object, the object acquires the `clmm.GalaxyCluster.profile` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in cl1.profile.colnames: cl1.profile[n].format = \"%6.3e\"\n",
    "cl1.profile.pprint(max_width=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the radially binned shear for the 3 configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "fsize = 14\n",
    "fig.gca().errorbar(profile1['radius'], profile1['gt'], yerr=profile1['gt_err'], marker='o', label='z_src = 0.8')\n",
    "fig.gca().errorbar(profile2['radius'], profile2['gt'], yerr=profile2['gt_err'], marker='o', \n",
    "                   label='z_src = Chang et al. (2013)')\n",
    "fig.gca().errorbar(profile3['radius'], profile3['gt'], yerr=profile3['gt_err'], marker='o', \n",
    "                   label='z_src = Chang et al. (2013) + photoz err  + shape noise')\n",
    "\n",
    "plt.gca().set_title(r'Binned shear of source galaxies', fontsize=fsize)\n",
    "plt.gca().set_xlabel(r'$r\\;[Mpc]$', fontsize=fsize)\n",
    "plt.gca().set_ylabel(r'$g_t$', fontsize=fsize)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the halo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition to be used with scipy.optimize.curve_fit\n",
    "def shear_profile_model(r, logm, z_src):\n",
    "    m = 10.**logm\n",
    "    gt_model = clmm.compute_reduced_tangential_shear(r,\n",
    "                                                     m, concentration,\n",
    "                                                     cluster_z, z_src, cosmo,\n",
    "                                                     delta_mdef=200,\n",
    "                                                     halo_profile_model='nfw')    \n",
    "    return gt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a halo mass - highlighting bias when not accounting for the source redshift distribution in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the best-fit mass using `scipy.optimize.curve_fit`.\n",
    "\n",
    "Here, to build the model we make the WRONG assumption that the average shear in bin $i$ equals the shear at the average redshift in the bin; i.e. we assume that $\\langle g_t\\rangle_i = g_t(\\langle z\\rangle_i)$. This should not impact `cluster 1` as all sources are located at the same redshift. However, this yields a bias in the reconstructed mass for `cluster 2` and `cluster 3`, where the sources followed the Chang et al. (2013) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 1:  ideal data\n",
    "popt1,pcov1 = fitters['curve_fit'](lambda r, logm:shear_profile_model(r, logm, profile1['z']), \n",
    "                    profile1['radius'], \n",
    "                    profile1['gt'], \n",
    "                    profile1['gt_err'], bounds=[13.,17.])\n",
    "#popt1,pcov1 = spo.curve_fit(lambda r, logm:shear_profile_model(r, logm, profile1['z']), \n",
    "#                    profile1['radius'], \n",
    "#                    profile1['gt'], \n",
    "#                    sigma=profile1['gt_err'], bounds=[13.,17.])\n",
    "\n",
    "m_est1 = 10.**popt1[0]\n",
    "m_est_err1 =  m_est1 * np.sqrt(pcov1[0][0]) * np.log(10) # convert the error on logm to error on m\n",
    "\n",
    "# Cluster 2:  ideal data with redshift distribution\n",
    "popt2,pcov2 = fitters['curve_fit'](lambda r, logm:shear_profile_model(r, logm, profile2['z']), \n",
    "                    profile2['radius'], \n",
    "                    profile2['gt'], \n",
    "                    profile2['gt_err'], bounds=[13.,17.])\n",
    "\n",
    "m_est2 = 10.**popt2[0]\n",
    "m_est_err2 =  m_est2 * np.sqrt(pcov2[0][0]) * np.log(10) # convert the error on logm to error on m\n",
    "\n",
    "# Cluster 3:  noisy data with redshift distribution\n",
    "popt3,pcov3 = fitters['curve_fit'](lambda r, logm:shear_profile_model(r, logm, profile3['z']), \n",
    "                    profile3['radius'], \n",
    "                    profile3['gt'], \n",
    "                    profile3['gt_err'], bounds=[13.,17.])\n",
    "\n",
    "m_est3 = 10.**popt3[0]\n",
    "m_est_err3 =  m_est3 * np.sqrt(pcov3[0][0]) * np.log(10) # convert the error on logm to error on m\n",
    "\n",
    "\n",
    "\n",
    "print(f'Best fit mass for cluster 1 = {m_est1:.2e} +/- {m_est_err1:.2e} Msun')\n",
    "print(f'Best fit mass for cluster 2 = {m_est2:.2e} +/- {m_est_err2:.2e} Msun')\n",
    "print(f'Best fit mass for cluster 3 = {m_est3:.2e} +/- {m_est_err3:.2e} Msun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the reconstructed mass is biased whenever the sources are not located at a single redshift as this was not accounted for in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the results\n",
    "\n",
    "For visualization purpose, we calculate the reduced tangential shear predicted by the model when using the average redshift of the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.logspace(-0.5, np.log10(5), 100)\n",
    "gt_model1 = clmm.compute_reduced_tangential_shear(rr,\n",
    "                                                  m_est1, concentration,\n",
    "                                                  cluster_z, np.mean(cl1.galcat['z']), cosmo,\n",
    "                                                  delta_mdef=200,\n",
    "                                                  halo_profile_model='nfw')\n",
    "\n",
    "gt_model2 = clmm.compute_reduced_tangential_shear(rr,\n",
    "                                                  m_est2, concentration,\n",
    "                                                  cluster_z, np.mean(cl2.galcat['z']), cosmo,\n",
    "                                                  delta_mdef=200,\n",
    "                                                  halo_profile_model='nfw')\n",
    "\n",
    "gt_model3 = clmm.compute_reduced_tangential_shear(rr,\n",
    "                                                  m_est3, concentration,\n",
    "                                                  cluster_z, np.mean(cl3.galcat['z']), cosmo,\n",
    "                                                  delta_mdef=200,\n",
    "                                                  halo_profile_model='nfw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize that prediction of reduced tangential shear along with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "axes[0].errorbar(profile1['radius'], profile1['gt'],profile1['gt_err'], color='red',\n",
    "                 label='ideal_data, M_input = %.3e Msun' % cluster_m, fmt='.')\n",
    "axes[0].plot(rr, gt_model1,color='red',\n",
    "             label='best fit model 1, M_fit = %.2e +/- %.2e' % (m_est1, m_est_err1))\n",
    "\n",
    "\n",
    "axes[0].errorbar(profile2['radius'], profile2['gt'],profile2['gt_err'], color='green',\n",
    "                  label='ideal_data_z, M_input = %.3e Msun' % cluster_m, fmt='.')\n",
    "axes[0].plot(rr, gt_model2, color='green',\n",
    "               label='best fit model 2, M_fit = %.2e +/- %.2e' % (m_est2, m_est_err2))\n",
    "axes[0].set_title('Ideal data w/wo src redshift distribution',fontsize=fsize)\n",
    "axes[0].semilogx()\n",
    "axes[0].semilogy()\n",
    "axes[0].legend(fontsize=fsize)\n",
    "axes[0].set_xlabel('R [Mpc]', fontsize=fsize)\n",
    "axes[0].set_ylabel('reduced tangential shear', fontsize=fsize)\n",
    "\n",
    "axes[1].errorbar(profile3['radius'], profile3['gt'],profile3['gt_err'], color='red',\n",
    "                label='noisy_data_z, M_input = %.3e Msun' % cluster_m, fmt='.')\n",
    "axes[1].plot(rr, gt_model3,color='red',\n",
    "             label='best fit model 3, M_fit = %.2e +/- %.2e' % (m_est3, m_est_err3))\n",
    "axes[1].set_title('Noisy data with src redshift distribution',fontsize=fsize)\n",
    "axes[1].semilogx()\n",
    "axes[1].semilogy()\n",
    "axes[1].legend(fontsize=fsize)\n",
    "axes[1].set_xlabel('R [Mpc]', fontsize=fsize)\n",
    "axes[1].set_ylabel('reduced tangential shear', fontsize=fsize)\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
